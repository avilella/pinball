##  These are the installation instructions for the pinball pipeline.
##  For questions/comments, email avilella@gmail.com
##  
##  Requirements
##   => a 64bit modern linux computer (or compute farm, tested on 2.6.18+ debian/ubuntu)
##   => a modern version of perl (tested on 5.8+)
##   => sqlite3 (tested on 3.3.8+) or mysql server (tested on 5.0+)
##  
##  Optional for compute farms:
##  
##   => mysql server         (sqlite can only handle a handful of concurrent jobs)
##   => farm queueing system (ehive has support for LSF, SGE* or Amazon cloud, email me for details)
##  
##  * for SGE, use http://raw.github.com/avilella/ensembl-hive/master/modules/Bio/EnsEMBL/Hive/Meadow/SGE.pm
##  
##  # NOTE: All instructions tested on bash terminal
##  
##  # Do a tar xzf or the pinball package on your home directory:
##  cd ~
##  tar xzf pinball.tar.gz
##  cd ~/pinball
##  
##  The pinball package contains some other programs and scripts that are not integrated in the pipeline but are just added for convenience in development and helping users analyse their data in different ways.

########################################
# USING SQLITE

# If you don't have a mysql server installed, you can use ensembl-hive
# with sqlite3. To install sqlite, and its DBD perl modules:

# On a Debian-based machine:
sudo apt-get install build-essential sqlite3 libsqlite3-dev perl-doc

# Then
mkdir ~/pinball/sqlite
./cpanm -L ~/pinball/sqlite DBD::SQLite

# This will create the modules somewhere like $HOME/pinball/sqlite/lib/perl5/x86_64-linux-thread-multi
find ~/pinball/sqlite -name DBD.pm
/home/user/pinball/sqlite/lib/perl5/i686-linux-gnu-thread-multi/DBI/DBD.pm

# Add that directory to the PERL5LIB as shown below:
PERL_SQLITE_MODULES_HERE=$HOME/pinball/sqlite/lib/perl5/i686-linux-gnu-thread-multi/

echo PINBALLPERL5LIB && export PERL5LIB=$HOME/pinball/modules:$HOME/pinball/ensembl_main/ensembl/modules:$HOME/pinball/ensembl_main/ensembl-hive/modules:$HOME/pinball/ensembl_main/ensembl-compara/modules:$HOME/pinball/bioperl-1.2.3:$HOME/pinball/BioPerl-1.6.1:$PERL_SQLITE_MODULES_HERE

# Set up the PATH
echo PINBALLPATH && export PATH=$PATH:$HOME/pinball/ensembl_main/ensembl-hive/scripts

# You should now be able to see the DBD::SQLite, ensembl-hive modules
# and beekeeper.pl script (q to quit):
perldoc Bio::EnsEMBL::Hive::Worker
perldoc DBD::SQLite
beekeeper.pl

# Check that the provided sga and bwa binaries run correctly in your 64bit computer:
# For bwa, try:
~/pinball/bwa/bwa index

# To recompile bwa:
sudo apt-get install zlib1g-dev
cd ~/pinball/bwa/
make clean; make
cd ~/pinball

# For sga, try:
export LD_LIBRARY_PATH=$HOME/pinball/sga/bamtools/lib
~/pinball/sga/src/sga

# To recompile sga, follow instructions here: https://raw.github.com/jts/sga/master/src/README

########################################
# EXAMPLE INPUT FILES:

# For some example fastq files, you can download these small datasets:
mkdir -p ~/pinball/somewhere/with/disk/space
cd ~/pinball/somewhere/with/disk/space
wget ftp://ftp.ebi.ac.uk/pub/databases/ensembl/avilella/pinball_example_data/example.encode.1pc.fastq.gz
wget ftp://ftp.ebi.ac.uk/pub/databases/ensembl/avilella/pinball_example_data/example.encode.1pm.fastq.gz
cd ~/pinball

########################################
# EXAMPLE REFERENCE:
cd ~/pinball/somewhere/with/disk/space
wget ftp://ftp.ebi.ac.uk/pub/databases/ensembl/avilella/pinball_example_data/human_g1k_v37_chr22.fasta.gz
~/pinball/bwa/bwa index human_g1k_v37_chr22.fasta.gz
cd ~/pinball


########################################
# INITIALIZE THE DATABASE:

# For the example data:
dbname=my_example_encode
tag=example_encode.1pc.1pm
perl ~/pinball/ensembl_main/ensembl-hive/scripts/init_pipeline.pl Pinball::PipeConfig::Pinball_conf -ensembl_cvs_root_dir $HOME/pinball/ensembl_main -pipeline_db -dbname=$dbname -hive_driver sqlite -password=foo -pipeline_name pinball -cluster_gigs 2 -cluster_procs 3 -cluster_queue foo -longest_n 1 -work_dir ~/pinball/somewhere/with/disk/space -seq ~/pinball/somewhere/with/disk/space/example.encode.1pc.fastq.gz:~/pinball/somewhere/with/disk/space/example.encode.1pm.fastq.gz -tag $tag -reference ~/pinball/somewhere/with/disk/space/human_g1k_v37_chr22.fasta.gz

# For your own data
dbname=my_whatever_name_I_want_to_give_to_the_db
tag=my_tag
perl ~/pinball/ensembl_main/ensembl-hive/scripts/init_pipeline.pl Pinball::PipeConfig::Pinball_conf -ensembl_cvs_root_dir $HOME/pinball/ensembl_main -pipeline_db -dbname=$dbname -hive_driver sqlite -password=foo -pipeline_name pinball -cluster_gigs 32 -cluster_procs 22 -cluster_queue foo -work_dir /somewhere/with/disk/space -seq /colon/separated/list/of/fastq/or/fasta/files/compressed/or/not/file1.fa:/another/file2.fq:/and/another/file3.fq.gz -tag $tag -reference /closest/genome/reference/that/has/been/indexed/with/bwa/file.fa

########################################
# START THE PINBALL PIPELINE

# Synchronize for the first time:
cd ~/pinball
beekeeper.pl -url sqlite:///my_example_encode -sync

# Loop through the process (here using local and 2 cpus, LSF is default):
cd ~/pinball
beekeeper.pl -url sqlite:///my_example_encode -loop -local -local_cpus 2

# Use Ctrl+C to stop it at any point. You can run beekeeper sync at any point to check the status.

########################################
# PIPELINE RESULTS

# The pipeline produces reconstructed regions for each clustered set of reads.
# After all the "walk" jobs have finished, you should be able to compile all the contigs using this command:
find ~/pinball/somewhere/with/disk/space -name "*.walks" | xargs cat > all.walks.fasta

